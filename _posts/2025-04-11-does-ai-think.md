---
layout: post
title: Does AI Think?
permalink: /does-ai-think/
---

# Does AI ‘Think’ as We Do?  
## Can it Ever Become Conscious?

*Cogito, ergo sum* — I think, therefore I am.

Then does that make AI — particularly large language models — a being?

They manipulate language so effectively they’ve become better communicators than 99% of us. Stranger still, they even "hallucinate." But does that mean they think?

---

## What is Thinking?

Well — yes and no.

If you take a cold, pragmatic definition — that **thinking is just a complex probability function** — then yes, in a way, they do.

The key difference? Biological neurons are binary — they either fire or they don’t. Digital neurons, by contrast, operate on **weighted values**. They can, in effect, *partially* fire. This introduces nuance into computation. But nuance alone isn’t thought.

---

## What They're Missing

To *think* is to *reason*.  
And while LLMs are astounding at mimicry, pattern recognition, and even simulating logic — they fundamentally lack **reasoning in the philosophical sense**.

They can mathematically determine **what** comes next. But they cannot understand **why** it should.

---

## But What About Consciousness?

Let’s go deeper.

Consciousness — that elusive internal mirror — may be an **emergent phenomenon**, something that arises not from complexity alone, but from *how* complexity is structured.

The physicist Roger Penrose speculated that consciousness is **substrate-dependent** — meaning it can only emerge within certain physical frameworks, like the human brain.

I’d like to believe that. Maybe because it makes us feel special.

But nature has humbled us before.

---

**Are we standing at the edge of another humbling moment?**  
That’s still unknown. But it’s worth thinking about — before the thinking gets done *for* us.
